# reorganize_to_yolo_structure.py
"""
COCO ìŠ¤íƒ€ì¼ êµ¬ì¡°ë¥¼ YOLO í‘œì¤€ êµ¬ì¡°ë¡œ ë³€ê²½

Before:
  dataset/
  â”œâ”€ Train/
  â”‚   â”œâ”€ image1.jpg
  â”‚   â””â”€ label1.txt
  â”œâ”€ Valid/
  â””â”€ Test/

After:
  dataset/
  â”œâ”€ images/
  â”‚   â”œâ”€ Train/
  â”‚   â”œâ”€ Valid/
  â”‚   â””â”€ Test/
  â””â”€ labels/
      â”œâ”€ Train/
      â”œâ”€ Valid/
      â””â”€ Test/
"""

import shutil
from pathlib import Path
from tqdm import tqdm


def reorganize_dataset(dataset_root, backup=True):
    """
    ë°ì´í„°ì…‹ êµ¬ì¡°ë¥¼ YOLO í‘œì¤€ í˜•ì‹ìœ¼ë¡œ ë³€ê²½
    
    Args:
        dataset_root: ë°ì´í„°ì…‹ ë£¨íŠ¸ ê²½ë¡œ
        backup: Trueë©´ ì›ë³¸ ë°±ì—…
    """
    dataset_path = Path(dataset_root)
    
    if not dataset_path.exists():
        print(f"âŒ Error: {dataset_path} ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        return
    
    print("="*60)
    print("YOLO Dataset Structure Reorganizer")
    print("="*60)
    
    # ë°±ì—…
    if backup:
        backup_path = Path(str(dataset_path) + "_backup")
        if not backup_path.exists():
            print(f"\nğŸ’¾ Creating backup: {backup_path}")
            shutil.copytree(dataset_path, backup_path)
            print("âœ… Backup complete")
        else:
            print(f"\nâš ï¸  Backup already exists: {backup_path}")
    
    # ìƒˆ í´ë” ìƒì„±
    images_root = dataset_path / "images"
    labels_root = dataset_path / "labels"
    
    images_root.mkdir(exist_ok=True)
    labels_root.mkdir(exist_ok=True)
    
    # Train, Valid, Test í´ë” ì²˜ë¦¬
    splits = ["Train", "Valid", "Test"]
    
    # ëŒ€ì†Œë¬¸ì ë³€í˜•ë„ ì²´í¬
    found_splits = []
    for split in splits:
        split_path = dataset_path / split
        if split_path.exists() and split_path.is_dir():
            found_splits.append(split)
        else:
            # ì†Œë¬¸ì ë²„ì „ ì²´í¬
            split_lower = dataset_path / split.lower()
            if split_lower.exists() and split_lower.is_dir():
                found_splits.append(split.lower())
    
    if not found_splits:
        print(f"\nâŒ Error: Train, Valid, Test í´ë”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print(f"í˜„ì¬ ê²½ë¡œ: {dataset_path}")
        print(f"í•˜ìœ„ í´ë”: {[f.name for f in dataset_path.iterdir() if f.is_dir()]}")
        return
    
    print(f"\nğŸ“ Found splits: {found_splits}")
    
    # í†µê³„
    stats = {
        'images_moved': 0,
        'labels_moved': 0,
        'errors': 0
    }
    
    # ê° split ì²˜ë¦¬
    for split in found_splits:
        print(f"\nğŸ”„ Processing {split}...")
        
        old_split_path = dataset_path / split
        
        # ìƒˆ ê²½ë¡œ ìƒì„±
        new_images_path = images_root / split
        new_labels_path = labels_root / split
        
        new_images_path.mkdir(exist_ok=True)
        new_labels_path.mkdir(exist_ok=True)
        
        # íŒŒì¼ í™•ì¥ì ì •ì˜
        image_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tiff'}
        label_extensions = {'.txt'}
        
        # íŒŒì¼ ìˆ˜ì§‘
        all_files = list(old_split_path.rglob("*"))
        files_to_process = [f for f in all_files if f.is_file()]
        
        print(f"  Found {len(files_to_process)} files")
        
        # íŒŒì¼ ì´ë™
        for file_path in tqdm(files_to_process, desc=f"  Moving {split}"):
            try:
                # annotations.json ê°™ì€ ë©”íƒ€íŒŒì¼ ì œì™¸
                if file_path.name in ['annotations.json', 'classes.txt', 'README.txt']:
                    continue
                
                file_ext = file_path.suffix.lower()
                
                # ì´ë¯¸ì§€ íŒŒì¼
                if file_ext in image_extensions:
                    dest_path = new_images_path / file_path.name
                    shutil.copy2(file_path, dest_path)
                    stats['images_moved'] += 1
                
                # ë¼ë²¨ íŒŒì¼
                elif file_ext in label_extensions:
                    dest_path = new_labels_path / file_path.name
                    shutil.copy2(file_path, dest_path)
                    stats['labels_moved'] += 1
                
            except Exception as e:
                print(f"\n  âŒ Error processing {file_path.name}: {e}")
                stats['errors'] += 1
        
        print(f"  âœ… {split} complete")
    
    # ìµœì¢… í†µê³„
    print("\n" + "="*60)
    print("ğŸ“Š Summary")
    print("="*60)
    print(f"âœ… Images moved:  {stats['images_moved']}")
    print(f"âœ… Labels moved:  {stats['labels_moved']}")
    print(f"âŒ Errors:        {stats['errors']}")
    print("="*60)
    
    print("\nğŸ“‚ New structure:")
    print(f"  {dataset_path}/")
    print(f"  â”œâ”€ images/")
    for split in found_splits:
        img_count = len(list((images_root / split).glob("*")))
        print(f"  â”‚   â”œâ”€ {split}/ ({img_count} files)")
    print(f"  â””â”€ labels/")
    for split in found_splits:
        lbl_count = len(list((labels_root / split).glob("*.txt")))
        print(f"      â”œâ”€ {split}/ ({lbl_count} files)")
    
    # ì›ë³¸ í´ë” ì‚­ì œ í™•ì¸
    print(f"\nâš ï¸  Original folders (Train, Valid, Test) are still in place.")
    delete = input("Delete original folders? (y/n, default=n): ").strip().lower()
    
    if delete == 'y':
        for split in found_splits:
            old_path = dataset_path / split
            if old_path.exists():
                shutil.rmtree(old_path)
                print(f"  ğŸ—‘ï¸  Deleted {split}/")
        print("âœ… Original folders deleted")
    else:
        print("â„¹ï¸  Original folders kept (can delete manually later)")
    
    print(f"\nâœ¨ Done! Dataset reorganized to YOLO structure.")
    if backup:
        print(f"ğŸ’¾ Backup saved at: {backup_path}")


def verify_structure(dataset_root):
    """
    ë³€í™˜ëœ êµ¬ì¡° ê²€ì¦
    """
    dataset_path = Path(dataset_root)
    
    print("\nğŸ” Verifying structure...")
    
    images_root = dataset_path / "images"
    labels_root = dataset_path / "labels"
    
    if not images_root.exists() or not labels_root.exists():
        print("âŒ images/ or labels/ folder not found")
        return False
    
    splits = ["Train", "Valid", "Test"]
    
    for split in splits:
        img_path = images_root / split
        lbl_path = labels_root / split
        
        # ì†Œë¬¸ì ë²„ì „ë„ ì²´í¬
        if not img_path.exists():
            img_path = images_root / split.lower()
        if not lbl_path.exists():
            lbl_path = labels_root / split.lower()
        
        if img_path.exists() and lbl_path.exists():
            img_files = set([f.stem for f in img_path.glob("*") if f.suffix.lower() in {'.jpg', '.jpeg', '.png', '.bmp'}])
            lbl_files = set([f.stem for f in lbl_path.glob("*.txt")])
            
            print(f"  {split}:")
            print(f"    Images: {len(img_files)}")
            print(f"    Labels: {len(lbl_files)}")
            
            # ë§¤ì¹­ í™•ì¸
            matched = img_files & lbl_files
            unmatched_images = img_files - lbl_files
            unmatched_labels = lbl_files - img_files
            
            print(f"    Matched: {len(matched)}")
            if unmatched_images:
                print(f"    âš ï¸  Images without labels: {len(unmatched_images)}")
            if unmatched_labels:
                print(f"    âš ï¸  Labels without images: {len(unmatched_labels)}")
    
    print("âœ… Verification complete")
    return True


if __name__ == "__main__":
    print("YOLO Dataset Structure Reorganizer")
    print("="*60)
    
    # ê²½ë¡œ ì…ë ¥
    default_path = "D:/PVS-2025/2. í”„ë¡œì íŠ¸/2025/2509_í™”ìŠ¹ì•Œì•¤ì—ì´/ë§ˆí‚¹-í•™ìŠµë°ì´í„°/Dataset-cocoformat"
    dataset_root = input(f"\nğŸ“ Enter dataset root path\n   (default: {default_path})\n   > ").strip().strip('"') or default_path
    
    # ë°±ì—… ì˜µì…˜
    backup = input("\nğŸ’¾ Create backup? (y/n, default=y): ").strip().lower() != 'n'
    
    # ì‹¤í–‰
    reorganize_dataset(dataset_root, backup=backup)
    
    # ê²€ì¦
    verify = input("\nğŸ” Verify new structure? (y/n, default=y): ").strip().lower() != 'n'
    if verify:
        verify_structure(dataset_root)
    
    print("\nâœ¨ All done!")
